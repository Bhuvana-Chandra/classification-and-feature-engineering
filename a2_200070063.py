# -*- coding: utf-8 -*-
"""A2_200070063.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aFoYbOLwWspOXtso12xKf7yIxUOVT61B

Importing the required libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sklearn as sk
import csv

"""Importing the train and test data"""

!wget https://www.ee.iitb.ac.in/~asethi/Dump/MouseTrain.csv \ -O train_data.csv#uploaded the data on colab
!wget https://www.ee.iitb.ac.in/~asethi/Dump/MouseTest.csv \ -O test_data.csv
train_data_url='https://www.ee.iitb.ac.in/~asethi/Dump/MouseTrain.csv'
train_data=pd.read_csv(train_data_url)
test_data_url='https://www.ee.iitb.ac.in/~asethi/Dump/MouseTest.csv'
test_data=pd.read_csv(test_data_url)
#test_data

"""Q2)Performing which variables are usefu,and which are not by chechking the correlation matrix between the features and deletingone of the two features if both of them are highly correlated"""

train_data_filled=train_data.fillna(0)#filling all the missing values with zeroes, incase if neccesary for later use 
corr_matrix=train_data.corr().abs()#obtaining correlation of all the features among them and taking the absoulte value of it just to know which features are highly correlated
upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape),k=1).astype(np.bool)) #https://www.projectpro.io/recipes/drop-out-highly-correlated-features-in-python
#taking only the upper triangular matrix as the correlation is taken with absolute value, it is symmetric and we will be able to delete one of the two features easily
print(upper_tri)
upper_tri

"""Droping one of the columns(features) which are higly correlated and modifying training dataset"""

to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]#https://www.projectpro.io/recipes/drop-out-highly-correlated-features-in-python
#dropping the columns(features) which are highly correlated with any of the other features
to_drop_indices=[train_data.columns.get_loc(col) for col in to_drop]#taking indices of all the dropped columns(features)
to_drop_indices
train_data[to_drop]

train_data_m1= train_data.drop(train_data.columns[to_drop_indices], axis=1)#dropping all the columns which are highly correlated but only the columns but not the rows with missing values
train_data_m1

"""Fninding number of missing columns in each column(feature) and dropping the columns which have large missing values, I have considered the threshold as 50 and deleted all columns which have more than 50 missing values in them"""

#https://cmdlinetips.com/2020/11/how-to-get-number-of-missing-values-in-each-column-in-pandas/
no_of_missing_values=train_data_m1.isna().sum()# knowing no.of missing values in each column
max_missing_values=50
cols_with_excess_missing_values=no_of_missing_values[no_of_missing_values >= max_missing_values].index.tolist()# getting columns which have more than the expected threshold of missing values
cols_with_excess_missing_values_indices=[train_data_m1.columns.get_loc(col) for col in cols_with_excess_missing_values]#getting indices of those columns with excess missing values
train_data_m2=train_data_m1.drop(train_data_m1.columns[cols_with_excess_missing_values_indices],axis=1)#dropping the columns with excess missing values
train_data_m2
miss=cols_with_excess_missing_values_indices
miss
train_data_m2#modified training data after deleting the columns with excess missing values
             # from the dataset in which already one of the each of the highly correlated columns(features) are already deleted

"""Q3) Using multivariate featureimputation, missing values are filled with the corresponding values calculated by iterative imputation in the column and later training data is updated

Also using MaxAbsScaler function, the feature values are normalized 
"""

from sklearn.experimental import enable_iterative_imputer
from sklearn.preprocessing import MaxAbsScaler
from sklearn.impute import IterativeImputer
imp =IterativeImputer(max_iter=20, random_state=0) #doing multivariate imputation to replace the missing values
train_data_class=['Genotype','Treatment_Behavior']#just taking classification columns
train_data_proteins=train_data_m2.drop(train_data_class,axis=1)#deleting classification columns from total dataset
train_data_columns=[column for column in train_data_proteins]
imp.fit(train_data[train_data_columns])#https://scikit-learn.org/stable/modules/impute.html
train_data_m3=imp.transform(train_data[train_data_columns])#assigning values for missing values using multivariate imputation
train_data_m3
train_data_m3.shape

scaler=MaxAbsScaler()
scaler.fit(train_data_m3)
train_data_m4=scaler.transform(train_data_m3)
train_data_m4
train_data_m4

"""Now, We modified test data such that it have only the columns which are in the modified training data after multivariate feature imputation, since the columns dont much contribute in classification

Also, the test data values of features are normalized
"""

from sklearn.preprocessing import MaxAbsScaler

# Find the common columns
common_columns=[col for col in train_data_m2.columns if col in test_data.columns] #common columns finding in test data such that all the features that are not contributing much are deleted
common_columns_indices=[test_data.columns.get_loc(col) for col in common_columns]#getting the indices of all the common columns(useful features)
common_columns_indices
test_data_class=['Genotype','Treatment_Behavior']
test_data_protiens=test_data.drop(test_data_class,axis=1)#getting only the features dataset
#test_data_m=test_data[common_columns]
test_data_m1=test_data[common_columns]#modifying the test data to have only the useful features
test_data_m2=test_data_m1.drop(test_data_class,axis=1)#dropping the classification columns for further computations
test_data_m3=test_data_m2.iloc[:,:].values#converting dataset intoa  2d array for computation purpose
scaler=MaxAbsScaler()
scaler.fit(test_data_m3)
test_data_m3=scaler.transform(test_data_m3)

print(test_data_m2.shape,test_data_m1.shape,test_data_m3.shape,test_data_protiens.shape)
test_data_m3

"""**Q5,Q6,Q8 for binary classification**

Using five-fold cross validation in GridSearch, found reasonable(bes) hyperparameters for the following models

a)Linear SVM with regularization as hyperparameter 

b) RBF kernel SVM with kernel width and regularization as hyperparameters 

c) Neural network with single ReLU hidden layer and Softmax output (hyperparameters: number of
neurons, weight decay) 

d) Random forest (max tree depth, max number of variables per node) 

After finding the best hyperparameters for each model, feature importance of each feature is also calculated in each model using coef_,permutation_importance_,coefs_,feature_importance functions(imported from scikit learn) respectively

Then later from the optimized hyperparamters model, classification for the test data samples is predicted and it is compared with the actual test data classes and AUC score and classifciation report is obtained
"""

from sklearn.model_selection import GridSearchCV#importing all the required libraries
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC, SVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report
from sklearn.inspection import permutation_importance
from sklearn.feature_selection import SelectFromModel
from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import LabelEncoder


binary_class_train=train_data.iloc[:,-2]# taking all the classification columns in training and test data
four_class_train=train_data.iloc[:,-1]
binary_class_test=test_data.iloc[:,-2]
four_class_test=test_data.iloc[:,-1]

# Train a Linear SVM model with hyperparameter tuning on the training data
linear_svc_model = SVC(kernel='linear')#creating an instance of the linear Support Vector Classification (SVC) model 
param_grid_linear_svm = {'C': [0.1, 1, 10]}#regularisation hyperparameter c
linear_svc_grid = GridSearchCV(linear_svc_model, param_grid_linear_svm, cv=5)#doing gridsearch for the model using linear svm
linear_svc_grid.fit(train_data_m4,binary_class_train)#fitting a Linear Support Vector Classification (LinearSVC) model using a grid search on the
                                                  #training data (train_data_m4) with corresponding target labels (four_class_train).
linear_svc_model = linear_svc_grid.best_estimator_# getting the best estimated hyperparameters
linear_svc_cv_results=linear_svc_grid.cv_results_#getting the cross validation results for various hyperparameters
linear_svc_best_hyp=linear_svc_grid.best_params_

# Train an SVM with RBF kernel model with hyperparameter tuning on the training data
rbf_svc_model = SVC(kernel='rbf')#creating an instance of the Support Vector Classification (SVC) model with a radial basis function (RBF) kernel.
param_grid_rbf_svm = {'C': [0.1, 1, 10], 'gamma': ['scale', 'auto']}#regularisation hyperparameter c and kernel width gamma
rbf_svc_grid = GridSearchCV(rbf_svc_model, param_grid_rbf_svm, cv=5)#doing gridsearch for model using svm with rbf kernel
rbf_svc_grid.fit(train_data_m4, binary_class_train)#fiitting a svc with rbf kernel model using gridsearch
rbf_svc_model = rbf_svc_grid.best_estimator_#etimating the best hyperparameters
rbf_svc_cv_results=rbf_svc_grid.cv_results_#getting the cross validation results for various hyperparameters
rbf_svc_best_hyp=rbf_svc_grid.best_params_

# Train a neural network model with hyperparameter tuning on the training data
nn_model = MLPClassifier(activation='relu', random_state=42,max_iter=10000)#creating an instance of neural network model with single RELU hidden layer
param_grid_nn = {'alpha': [0.0001, 0.001, 0.01], 'hidden_layer_sizes': [(50,), (100,), (200,)]}#number of neurons in hudden layers represented as hidden_layer_sizes 
                                                                                            #and weight decay represented as alpha
nn_grid = GridSearchCV(nn_model, param_grid_nn, cv=5)#doing gridsearch for neural network model
nn_grid.fit(train_data_m4,binary_class_train)#fiiting the model of neural network with single hidden layer uing gridsearch
nn_model = nn_grid.best_estimator_#estimating best hyperparameters
nn_cv_results=nn_grid.cv_results_#getting the cross validation results for various hyperparameters
nn_best_hyp=nn_grid.best_params_

# Train a Random Forest model with hyperparameter tuning on the training data
rf_model = RandomForestClassifier(random_state=42)#creating an instance of random forest model
param_grid_rf = {'n_estimators': [50, 100, 200], 'max_depth': [5,10,20]}#maximum no.of variables per node represented as n_estimators 
                                                                     # mximum tree depth represented as max_depth
rf_grid = GridSearchCV(rf_model, param_grid_rf, cv=5)#doing gridsearch on randomforest model
rf_grid.fit(train_data_m4,binary_class_train)#fitting the model of randomforest using gridsearch
rf_model = rf_grid.best_estimator_#estimating the best hyperparameters
rf_cv_results=rf_grid.cv_results_#getting the cross validation results for various hyperparameters
rf_best_hyp=rf_grid.best_params_


#getting best features for all the models
linear_svc_best_fea=linear_svc_model.coef_
rbf_svc_best_fea=permutation_importance(rbf_svc_grid, train_data_m4, binary_class_train, n_repeats=10, random_state=0)
nn_best_fea= nn_model.coefs_[0]
rf_best_fea = rf_model.feature_importances_


# Test the models on the testing data
linear_svc_y_pred = linear_svc_model.predict(test_data_m3)#testing and predicting the testdata on all four models
rbf_svc_y_pred = rbf_svc_model.predict(test_data_m3)
nn_y_pred = nn_model.predict(test_data_m3)
rf_y_pred = rf_model.predict(test_data_m3)


#converting classes into labels for calculating AUC score in binary classification
le = LabelEncoder()
bi_cls_tr_en=le.fit_transform(binary_class_train)
bi_cls_te_en=le.fit_transform(binary_class_test)
#bi_cls_tr_en=le.fit_transform(binary_class_train)
#bi_cls_tr_en=le.fit_transform(binary_class_train)
li_svc_y_pred_en=le.fit_transform(linear_svc_y_pred)
rbf_svc_y_pred_en=le.fit_transform(rbf_svc_y_pred)
nn_y_pred_en=le.fit_transform(nn_y_pred)
rf_y_pred_en=le.fit_transform(rf_y_pred)


# Print the best hyperparameters and the classification report for each model
print("Linear SVM Best Hyperparameters:", linear_svc_grid.best_params_)
print("Linear SVM Classification Report:\n", classification_report(binary_class_test, linear_svc_y_pred))
print("Linear SVM AUC Score",roc_auc_score(bi_cls_te_en,li_svc_y_pred_en))
print("Linear SVM cross validation results:\n",linear_svc_cv_results)
print("SVM with RBF Kernel Best Hyperparameters:", rbf_svc_grid.best_params_)
print("SVM with RBF Kernel Classification Report:\n", classification_report(binary_class_test, rbf_svc_y_pred))
print("SVM with RBF Kernel AUC Score",roc_auc_score(bi_cls_te_en,rbf_svc_y_pred_en))
print("SVM with RBF Kernel cross validation results:\n",rbf_svc_cv_results)
print("Neural Network Best Hyperparameters:", nn_grid.best_params_)
print("Neural Network Classification Report:\n", classification_report(binary_class_test, nn_y_pred))
print("Neural Network AUC Score",roc_auc_score(bi_cls_te_en,nn_y_pred_en))
print("Neural Network cross validaion results:\n",nn_cv_results)
print("Random Forest Best Hyperparameters:", rf_grid.best_params_)
print("Random Forest Classification AUC Score",roc_auc_score(bi_cls_te_en,rf_y_pred_en))
print("Random Forest cross validation results:\n",rf_cv_results)
print("Feature importance in Linear SVM:\n",linear_svc_best_fea)
print("Feature importance in SVM with RBF Kernel:\n",rbf_svc_best_fea)
print("Feature importance in Neural Network:\n",nn_best_fea)
print("Feature importance in Random Forest Classification:\n",rf_best_fea)
lin_svc_best_fea_flat = [item for sublist in linear_svc_best_fea for item in sublist]

# create a figure with two subplots
fig, axs = plt.subplots(1, 2, figsize=(10, 5))

# plot first plot on first subplot
axs[0].plot(range(len(lin_svc_best_fea_flat)), lin_svc_best_fea_flat)
axs[0].set_title('linear svm feature importances')

# plot second plot on second subplot
axs[1].plot(range(len(rf_best_fea)), rf_best_fea)
axs[1].set_title('random forest feature importances')

plt.show()

"""**Q5,Q6,Q8** for four classes classification

Similar to the above mentioned process, same is done with this classification except that the there are four different classes that are compared

We use accuracy as the measure for multivariable classification, which is th optimum metric to consider in this case

And later, from the optimized hyperparamters model, classification for the test data samples is predicted and it is compared with the actual test data classes and AUC score and classifciation report is obtained
"""

from sklearn.model_selection import GridSearchCV#importing all the required libraries
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC, SVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report

binary_class_train=train_data.iloc[:,-2]# taking all the classification columns in training and test data
four_class_train=train_data.iloc[:,-1]
binary_class_test=test_data.iloc[:,-2]
four_class_test=test_data.iloc[:,-1]

# Train a Linear SVM model with hyperparameter tuning on the training data
linear_svc_model =SVC(kernel='linear')#creating an instance of the linear Support Vector Classification (SVC) model
param_grid_linear_svm = {'C': [0.1, 1, 10]}#regularisation hyperparameter c 
linear_svc_grid = GridSearchCV(linear_svc_model, param_grid_linear_svm, cv=5)#doing gridsearch for the model using linear svm
linear_svc_grid.fit(train_data_m4,four_class_train)#fitting a Linear Support Vector Classification (LinearSVC) model using a grid search on the
                                                  #training data (train_data_m4) with corresponding target labels (four_class_train).
linear_svc_model = linear_svc_grid.best_estimator_# getting the best estimated hyperparameters
linear_svc_cv_results=linear_svc_grid.cv_results_#getting the cross validation results for various hyperparameters
linear_svc_best_hyp=linear_svc_grid.best_params_

# Train an SVM with RBF kernel model with hyperparameter tuning on the training data
rbf_svc_model = SVC(kernel='rbf')#creating an instance of the Support Vector Classification (SVC) model with a radial basis function (RBF) kernel.
param_grid_rbf_svm = {'C': [0.1, 1, 10], 'gamma': ['scale', 'auto']}#regularisation hyperparameter c and kernel width gamma
rbf_svc_grid = GridSearchCV(rbf_svc_model, param_grid_rbf_svm, cv=5)#doing gridsearch for model using svm with rbf kernel
rbf_svc_grid.fit(train_data_m4, four_class_train)#fiitting a svc with rbf kernel model using gridsearch
rbf_svc_model = rbf_svc_grid.best_estimator_#etimating the best hyperparameters
rbf_svc_cv_results=rbf_svc_grid.cv_results_#getting the cross validation results for various hyperparameters
rbf_svc_best_hyp=rbf_svc_grid.best_params_

# Train a neural network model with hyperparameter tuning on the training data
nn_model = MLPClassifier(activation='relu', random_state=42,max_iter=10000)#creating an instance of neural network model with single RELU hidden layer
param_grid_nn = {'alpha': [0.0001, 0.001, 0.01], 'hidden_layer_sizes': [(50,), (100,), (200,)]}#number of neurons in hudden layers represented as hidden_layer_sizes 
                                                                                            #and weight decay represented as alpha
nn_grid = GridSearchCV(nn_model, param_grid_nn, cv=5)#doing gridsearch for neural network model
nn_grid.fit(train_data_m4,four_class_train)#fiiting the model of neural network with single hidden layer uing gridsearch
nn_model = nn_grid.best_estimator_#estimating best hyperparameters
nn_cv_results=nn_grid.cv_results_#getting the cross validation results for various hyperparameters
nn_best_hyp=nn_grid.best_params_

# Train a Random Forest model with hyperparameter tuning on the training data
rf_model = RandomForestClassifier(random_state=42)#creating an instance of random forest model
param_grid_rf = {'n_estimators': [50, 100, 200], 'max_depth': [5,10,20]}#maximum no.of variables per node represented as n_estimators 
                                                                     # mximum tree depth represented as max_depth
rf_grid = GridSearchCV(rf_model, param_grid_rf, cv=5)#doing gridsearch on randomforest model
rf_grid.fit(train_data_m4,four_class_train)#fitting the model of randomforest using gridsearch
rf_model = rf_grid.best_estimator_#estimating the best hyperparameters
rf_cv_results=rf_grid.cv_results_#getting the cross validation results for various hyperparameters
rf_best_hyp=rf_grid.best_params_

#getting feature importance in all the models
linear_svc_best_fea=linear_svc_model.coef_
rbf_svc_best_fea=permutation_importance(rbf_svc_grid, train_data_m4, binary_class_train, n_repeats=10, random_state=0)
nn_best_fea= nn_model.coefs_[0]
rf_best_fea = rf_model.feature_importances_

# Test the models on the testing data
linear_svc_y_pred = linear_svc_model.predict(test_data_m3)#testing and predicting the testdata on all four models
rbf_svc_y_pred = rbf_svc_model.predict(test_data_m3)
nn_y_pred = nn_model.predict(test_data_m3)
rf_y_pred = rf_model.predict(test_data_m3)


# Print the best hyperparameters and the classification report for each model
print("Linear SVM Best Hyperparameters:", linear_svc_grid.best_params_)
print("Linear SVM Classification Report:\n", classification_report(four_class_test, linear_svc_y_pred))
print("SVM with RBF Kernel Best Hyperparameters:", rbf_svc_grid.best_params_)
print("SVM with RBF Kernel Classification Report:\n", classification_report(four_class_test, rbf_svc_y_pred))
print("Neural Network Best Hyperparameters:", nn_grid.best_params_)
print("Neural Network Classification Report:\n", classification_report(four_class_test, nn_y_pred))
print("Random Forest Best Hyperparameters:", rf_grid.best_params_)
print("Random Forest Classification Report:\n", classification_report(four_class_test, rf_y_pred))
print("Feature importance in Linear SVM:\n",linear_svc_best_fea)
print("Feature importance in SVM with RBF Kernel:\n",rbf_svc_best_fea)
print("Feature importance in Neural Network:\n",nn_best_fea)
print("Feature importance in Random Forest Classification:\n",rf_best_fea)
lin_svc_best_fea_flat = [item for sublist in linear_svc_best_fea for item in sublist]

# create a figure with two subplots
fig, axs = plt.subplots(1, 2, figsize=(10, 5))

# plot first plot on first subplot
axs[0].plot(range(len(lin_svc_best_fea_flat)), lin_svc_best_fea_flat)
axs[0].set_title('linear svm feature importances')

# plot second plot on second subplot
axs[1].plot(range(len(rf_best_fea)), rf_best_fea)
axs[1].set_title('random forest feature importances')

plt.show()

"""**Q7**

Obtaining important features(best features) from the models for Linear SVM and RandomForestClassifier, We won't be able to get best features for SVM with RBF kernel and Neural Networks with single ReLU hidden layer and Softmax output from RFECV function, since they does compute and obtain any best features 
"""

from sklearn.datasets import make_friedman1
from sklearn.metrics import f1_score
from sklearn.feature_selection import RFECV
from sklearn.feature_selection import SelectFromModel
from sklearn.svm import SVC
from sklearn.preprocessing import LabelEncoder

linear_svm_best_fr=SVC(kernel='linear',C=10)
rfecv_linear_svm_fr=RFECV(estimator=linear_svm_best_fr,step=1, cv=5, scoring='accuracy')
rfecv_linear_svm_fr.fit(train_data_m4,four_class_train)
rfecv_linear_svm_fr.support_

linear_svm_best_bi=SVC(kernel='linear',C=10)
rfecv_linear_svm_bi=RFECV(estimator=linear_svm_best_bi, step=1, cv=5, scoring='accuracy')
rfecv_linear_svm_bi.fit(train_data_m4,four_class_train)
rfecv_linear_svm_bi.support_

rf_svm_best_bi=RandomForestClassifier(n_estimators=100,max_depth=10)
rfecv_rf_svm_bi=RFECV(estimator=rf_svm_best_bi,step=1,cv=5,scoring='accuracy')
rfecv_rf_svm_bi.fit(train_data_m4,binary_class_train)
rfecv_rf_svm_bi.support_


rf_svm_best_fr=RandomForestClassifier(n_estimators=200,max_depth=10)
rfecv_rf_svm_fr=RFECV(estimator=rf_svm_best_fr,step=1,cv=5,scoring='accuracy')
rfecv_rf_svm_fr.fit(train_data_m4,binary_class_train)
rfecv_rf_svm_fr.support_
print("best features linear svm in binary classification:\n",rfecv_linear_svm_bi.support_)
print("best features linear svm in four classification:\n",rfecv_linear_svm_fr.support_)
print("best features randomforest in binary classification:\n",rfecv_rf_svm_bi.support_)
print("best features randomforest in four classification:\n",rfecv_rf_svm_fr.support_)
#rf_best=RandomForestClassifier()

"""Objective 2
Q9)Importing the hymenoptera_data_folder

Import required libraries
"""

# License: BSD
# Author: Sasank Chilamkurthy

from __future__ import print_function, division

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import torch.backends.cudnn as cudnn
import numpy as np
import torchvision
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt
import time
import os
import copy

cudnn.benchmark = True
plt.ion()   # interactive mode

"""Load the data 
Normalization and Agumentation of the data


"""

!wget "https://download.pytorch.org/tutorial/hymenoptera_data.zip"

!unzip hymenoptera_data.zip

# Data augmentation and normalization for training
# Just normalization for validation
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),#augmentation of data
        transforms.RandomHorizontalFlip(),#augmentation of data
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
}

data_dir = 'hymenoptera_data'
image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),
                                          data_transforms[x])
                  for x in ['train', 'val']}
dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,
                                             shuffle=True, num_workers=4)
              for x in ['train', 'val']}
dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}
class_names = image_datasets['train'].classes

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

"""Function to visualize a few images"""

def imshow(inp, title=None):
    """Imshow for Tensor."""
    inp = inp.numpy().transpose((1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    inp = std * inp + mean
    inp = np.clip(inp, 0, 1)
    plt.imshow(inp)
    if title is not None:
        plt.title(title)
    plt.pause(0.001)  # pause a bit so that plots are updated


# Get a batch of training data
inputs, classes = next(iter(dataloaders['train']))

# Make a grid from batch
out = torchvision.utils.make_grid(inputs)

imshow(out, title=[class_names[x] for x in classes])

"""Training model with ResNet as Fixed Feature Extractor

Loading pretrained ResNet model for feature extraction
"""

model_conv = torchvision.models.resnet18(pretrained=True)
for param in model_conv.parameters():
    param.requires_grad = False

# Parameters of newly constructed modules have requires_grad=True by default
num_ftrs = model_conv.fc.in_features
model_conv.fc = nn.Linear(num_ftrs, 2)

model_conv = model_conv.to(device)

criterion = nn.CrossEntropyLoss()

# Observe that only parameters of final layer are being optimized as
# opposed to before.
optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)

# Decay LR by a factor of 0.1 every 7 epochs
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)

"""Function for training the models"""

def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    since = time.time()

    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    for epoch in range(num_epochs):
        print(f'Epoch {epoch}/{num_epochs - 1}')
        print('-' * 10)

        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode

            running_loss = 0.0
            running_corrects = 0

            # Iterate over data.
            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                # zero the parameter gradients
                optimizer.zero_grad()

                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                # statistics
                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)
            if phase == 'train':
                scheduler.step()

            epoch_loss = running_loss / dataset_sizes[phase]
            epoch_acc = running_corrects.double() / dataset_sizes[phase]

            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

            # deep copy the model
            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())

        print()

    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val Acc: {best_acc:4f}')

    # load best model weights
    model.load_state_dict(best_model_wts)
    return model

model_ft = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler,
                       num_epochs=5)

"""Function to visualize the predictions of model for few images"""

def visualize_model(model, num_images=6):
    was_training = model.training
    model.eval()
    images_so_far = 0
    fig = plt.figure()

    with torch.no_grad():
        for i, (inputs, labels) in enumerate(dataloaders['val']):
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            for j in range(inputs.size()[0]):
                images_so_far += 1
                ax = plt.subplot(num_images//2, 2, images_so_far)
                ax.axis('off')
                ax.set_title(f'predicted: {class_names[preds[j]]}')
                imshow(inputs.cpu().data[j])

                if images_so_far == num_images:
                    model.train(mode=was_training)
                    return
        model.train(mode=was_training)

visualize_model(model_conv)
plt.ioff()
plt.show()

"""Function to extract the ResNet18 features for a given input image"""

pretrained_model= torchvision.models.resnet18(pretrained=True)#load resnet model
last_layer=pretrained_model._modules.get('avgpool')#avgpool is at the end of resnet
pretrained_model.eval()



from PIL import Image
from torchvision import transforms
import torch
transform=transforms.Compose([
     transforms.Resize((22,224)),
     transforms.ToTensor(),
     transforms.Normalize(mean=[0.48,0.46,0.47],
                               std=[0.22,0.29,0.27])
])

def getfeatures(image_name):
  image=Image.open(image_name)
  #converting image by normalizeing, and using totensor
  final_image=transform(image).unsqueeze(0)
  feature_vector=torch.Tensor(512).fillna_(0)#vector of zeroes holding feature vector
  def copy_data(a,b,c):
    feature_vector.copy_(c.data.reshape(c.data.size(1)))
  attachment=last_layer.register_forward_hook(copy_data)#attach the function to the layer
  pretrained_model(final_image)#run the model on the transoformed image
  attachment.remove()#remove our copy function from the layer
  return feature_vector.detach().cpu().numpy()


#https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/
#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html

"""All the references and explainations for the code are mentioned near the code itself

Took some ideas for coding in objective 2 from Prajwal Kalpande(roll number :200070028)

link for my recording - https://drive.google.com/file/d/159mhFxSB5aROHirijtOsyBiZ2GRR6lkJ/view?usp=sharing
"""